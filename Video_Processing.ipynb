{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers, optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6295417529801715650\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13717521504129066984\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_process(img,r_size,c_size):\n",
    "    scaled_image = cv2.resize(img, (r_size, c_size))\n",
    "    #rot_image = np.rot90(scaled_image,-1)\n",
    "    return scaled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dire = ''\n",
    "filename = 'yeah2.mov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_data(dire = dire, filename = filename,r_size=224,c_size=224):\n",
    "    file = dire+ filename\n",
    "    vidcap = cv2.VideoCapture(file)\n",
    "    flag = True\n",
    "    image_list = []\n",
    "    cnt = 0\n",
    "    while flag:\n",
    "        flag,img = vidcap.read()\n",
    "        if flag:\n",
    "            image_list += [image_process(img,r_size,c_size)]\n",
    "            cnt += 1\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    image_list = extract_image_data(dire,filename)\n",
    "    print(image_list[0].shape)\n",
    "    print(len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    imgplot = plt.imshow(image_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "files = [f for f in listdir('./') if isfile(join('./', f)) if f[-3:] == 'mov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fist.mov',\n",
       " 'fist1.mov',\n",
       " 'fist2.mov',\n",
       " 'five.mov',\n",
       " 'five2.mov',\n",
       " 'thumb2.mov',\n",
       " 'yeah2.mov']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.sort()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fist.mov fist 0 fist\n",
      "fist1.mov fist 0 fist\n",
      "fist2.mov fist 0 fist\n",
      "five.mov five 1 five\n",
      "five2.mov five 1 five\n",
      "thumb2.mov thumb 2 thumb\n",
      "yeah2.mov yeah 3 yeah\n"
     ]
    }
   ],
   "source": [
    "image_dataset = []\n",
    "category_dataset = []\n",
    "proj = {}\n",
    "conv = {}\n",
    "for filename in files:\n",
    "    image_list = extract_image_data(dire,filename)\n",
    "    image_dataset += image_list\n",
    "    gesture = filename.split('.')[0]\n",
    "    while not gesture[-1].isalpha():\n",
    "        gesture = gesture[:-1]\n",
    "    if gesture not in conv:\n",
    "        conv[gesture] = len(conv.keys())\n",
    "    proj[conv[gesture]] = gesture\n",
    "    category_dataset += [conv[gesture] for _ in image_list]\n",
    "    print(filename,gesture,conv[gesture],proj[conv[gesture]])\n",
    "image_dataset = np.asarray(image_dataset)\n",
    "category_dataset = np.asarray(category_dataset)\n",
    "category_dataset = keras.utils.to_categorical(category_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'fist', 1: 'five', 2: 'thumb', 3: 'yeah'}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fist': 0, 'five': 1, 'thumb': 2, 'yeah': 3}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5094, 224, 224, 3)\n",
      "(5094, 4)\n"
     ]
    }
   ],
   "source": [
    "print(image_dataset.shape)\n",
    "print(category_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_size=224\n",
    "c_size=224\n",
    "model = keras.applications.MobileNet(include_top=False,  weights='imagenet', input_shape=(r_size, c_size, 3),  pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 27s, sys: 3min 21s, total: 20min 49s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_input = model.predict(image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "indices = numpy.random.permutation(processed_input.shape[0])\n",
    "ratio = 0.8\n",
    "training_idx, test_idx = indices[:int(processed_input.shape[0]*ratio)], indices[int(processed_input.shape[0]*ratio):]\n",
    "x_train, x_test = processed_input[training_idx,:], processed_input[test_idx,:]\n",
    "y_train, y_test = category_dataset[training_idx,:], category_dataset[test_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(5094, 7, 7, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(image_dataset[0].shape)\n",
    "print(processed_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5094, 4)\n"
     ]
    }
   ],
   "source": [
    "print(category_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = models.Sequential()\n",
    "top_model.add(layers.Flatten(input_shape=(7, 7, 1024)))\n",
    "top_model.add(layers.Dense(128, activation='relu'))\n",
    "top_model.add(layers.Dense(128, activation='relu'))\n",
    "#top_model.add(layers.Dropout(0.6))\n",
    "top_model.add(layers.Dense(128, activation='relu'))\n",
    "top_model.add(layers.Dropout(0.6))\n",
    "top_model.add(layers.Dense(64, activation='relu'))\n",
    "top_model.add(layers.Dense(len(proj), activation='softmax'))\n",
    "\n",
    "top_model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4075 samples, validate on 1019 samples\n",
      "Epoch 1/1\n",
      "4075/4075 [==============================] - 2s 579us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "[0 1 1 1 0 1 0 0 0 0 3 0 1 1 0 1 0 0 0 3 1 0 2 0 0 0 3 0 2 0]\n",
      "[0 1 1 1 0 1 0 0 0 0 3 0 1 1 0 1 0 0 0 3 1 0 2 0 0 0 3 0 2 0]\n",
      "Train on 4075 samples, validate on 1019 samples\n",
      "Epoch 1/1\n",
      "4075/4075 [==============================] - 2s 570us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "[0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 3 1 2 0 1 1 1 1 0 2 2 0 0 0]\n",
      "[0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 3 1 2 0 1 1 1 1 0 2 2 0 0 0]\n",
      "Train on 4075 samples, validate on 1019 samples\n",
      "Epoch 1/1\n",
      "4075/4075 [==============================] - 2s 587us/step - loss: 1.2067e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "[2 3 0 0 3 1 0 1 1 0 1 0 0 1 1 1 0 0 2 0 0 0 0 0 0 1 1 3 0 0]\n",
      "[2 3 0 0 3 1 0 1 1 0 1 0 0 1 1 1 0 0 2 0 0 0 0 0 0 1 1 3 0 0]\n",
      "Train on 4075 samples, validate on 1019 samples\n",
      "Epoch 1/1\n",
      "4075/4075 [==============================] - 2s 566us/step - loss: 1.1936e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "[0 3 0 0 1 0 0 0 1 0 3 0 0 0 0 0 0 1 0 0 3 1 0 0 1 0 0 0 1 0]\n",
      "[0 3 0 0 1 0 0 0 1 0 3 0 0 0 0 0 0 1 0 0 3 1 0 0 1 0 0 0 1 0]\n",
      "Train on 4075 samples, validate on 1019 samples\n",
      "Epoch 1/1\n",
      "4075/4075 [==============================] - 2s 599us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "[1 1 0 0 1 0 0 1 1 0 2 3 0 1 0 0 1 1 0 1 1 0 0 0 2 0 3 3 1 1]\n",
      "[1 1 0 0 1 0 0 1 1 0 2 3 0 1 0 0 1 1 0 1 1 0 0 0 2 0 3 3 1 1]\n",
      "Train on 4075 samples, validate on 1019 samples\n",
      "Epoch 1/1\n",
      "4075/4075 [==============================] - 2s 576us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "[1 1 1 2 0 0 1 3 0 3 0 0 0 1 0 3 1 0 0 0 0 0 0 0 1 0 1 1 0 1]\n",
      "[1 1 1 2 0 0 1 3 0 3 0 0 0 1 0 3 1 0 0 0 0 0 0 0 1 0 1 1 0 1]\n",
      "Train on 4075 samples, validate on 1019 samples\n",
      "Epoch 1/1\n",
      "2752/4075 [===================>..........] - ETA: 0s - loss: 8.4696e-07 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    top_model.fit(x_train, y_train, epochs=1, batch_size=64, verbose=1,validation_data=(x_test, y_test))\n",
    "    print(top_model.predict_classes(x_test[_*30:_*30+30]))\n",
    "    print(np.asarray([sum([int((i)*val[i]) for i in range(4)]) for val in y_test[_*30:_*30+30]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [proj[i] for i in top_model.predict_classes(processed_input)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save trained model\n",
    "from keras.models import load_model\n",
    "\n",
    "top_model.save('top_model.h5')\n",
    "del top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('proj.json', 'w') as fp:\n",
    "    json.dump(proj, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load trained model\n",
    "top_model = load_model('top_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_command(img,r_size=224,c_size=224):\n",
    "    scaled_image = cv2.resize(img, (r_size, c_size))\n",
    "    cmd_id = top_model.predict_classes(model.predict(np.asarray([scaled_image])))[0]\n",
    "    return cmd_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "frame = image_dataset[1200]\n",
    "cmd_id = get_command(frame)\n",
    "cmd = proj[cmd_id]\n",
    "print(cmd)\n",
    "plt.imshow(cv2.putText(frame,cmd, (120,120), cv2.FONT_HERSHEY_SIMPLEX, 2, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a = model.predict(np.asarray([cv2.resize(frame, (r_size, c_size))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset[530].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture('fist.mov')\n",
    "flag = True\n",
    "while flag:\n",
    "    flag,frame = vidcap.read()\n",
    "    if flag:\n",
    "        cmd_id = get_command(frame)\n",
    "        cmd = proj[cmd_id]\n",
    "        print(cmd)\n",
    "        plt.imshow(cv2.putText(frame,cmd, (120,120), cv2.FONT_HERSHEY_SIMPLEX, 2, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
